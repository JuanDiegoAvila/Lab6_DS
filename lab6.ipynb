{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6 - Análisis de Redes Sociales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bernardo = pd.read_csv('./data/bernardoArevalo.csv')\n",
    "sandra = pd.read_csv('./data/sandraTorres.csv')\n",
    "trafico = pd.read_csv('./data/traficogt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernardo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_urls(text):\n",
    "    # Eliminar URLs que comienzan con http o https\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Eliminar URLs que comienzan con www\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "bernardo['rawContent'] = bernardo['rawContent'].apply(remove_urls)\n",
    "sandra['rawContent'] = sandra['rawContent'].apply(remove_urls)\n",
    "trafico['rawContent'] = trafico['rawContent'].apply(remove_urls)\n",
    "\n",
    "\n",
    "# Eliminar caracteres especiales como #, @, &, y apóstrofes.\n",
    "bernardo['rawContent'] = bernardo['rawContent'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "sandra['rawContent'] = sandra['rawContent'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "trafico['rawContent'] = trafico['rawContent'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"  \n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "bernardo['rawContent'] = bernardo['rawContent'].apply(remove_emojis)\n",
    "sandra['rawContent'] = sandra['rawContent'].apply(remove_emojis)\n",
    "trafico['rawContent'] = trafico['rawContent'].apply(remove_emojis)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwordsES = stopwords.words('spanish')\n",
    "stopwordsEN = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    clean_words = [word for word in words if word not in stopwordsES]\n",
    "    clean_words = [word for word in clean_words if word not in stopwordsEN]\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "bernardo['rawContent'] = bernardo['rawContent'].apply(remove_stopwords)\n",
    "sandra['rawContent'] = sandra['rawContent'].apply(remove_stopwords)\n",
    "trafico['rawContent'] = trafico['rawContent'].apply(remove_stopwords)\n",
    "\n",
    "# Convertir a mayúsculas\n",
    "bernardo['rawContent'] = bernardo['rawContent'].str.upper()\n",
    "sandra['rawContent'] = sandra['rawContent'].str.upper()\n",
    "trafico['rawContent'] = trafico['rawContent'].str.upper()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bernardo['rawContent'].head())\n",
    "print(sandra['rawContent'].head())\n",
    "print(trafico['rawContent'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernardo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandra.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafico.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = trafico.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Matriz de correlación\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.scatterplot(data=trafico, x='retweetCount', y='likeCount')\n",
    "plt.title(\"Relación entre Retweets y Likes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyword_lluvia = [\"LLUVIA\", \"LLOVIENDO\", \"MOJADO\"]\n",
    "keyword_trafico = [\"TRAFICO\", \"CONGESTIÓN\", \"ATASCADO\"]\n",
    "\n",
    "trafico['lluvia'] = trafico['rawContent'].apply(lambda x: any(keyword in x for keyword in keyword_lluvia))\n",
    "trafico['trafico'] = trafico['rawContent'].apply(lambda x: any(keyword in x for keyword in keyword_trafico))\n",
    "\n",
    "daily_counts = trafico.groupby(trafico['date'].astype('datetime64').dt.date)[['lluvia', 'trafico']].sum()\n",
    "\n",
    "# Graficar menciones de lluvia\n",
    "plt.figure(figsize=(15, 7))\n",
    "daily_counts['lluvia'].plot(label='Menciones de lluvia', color='blue')\n",
    "plt.title('Menciones diarias relacionadas con lluvia')\n",
    "plt.ylabel('Número de menciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Graficar menciones de tráfico\n",
    "plt.figure(figsize=(15, 7))\n",
    "daily_counts['trafico'].plot(label='Menciones de tráfico', color='red')\n",
    "plt.title('Menciones diarias relacionadas con tráfico')\n",
    "plt.ylabel('Número de menciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palabras clave relacionadas con el socavón y la universidad\n",
    "keywords_sinkhole = ['SOCAVÓN', 'ZONA 5']\n",
    "keywords_university = ['UVG', 'ZONA 16', 'LANDIVAR', 'ZONA 15']\n",
    "\n",
    "# Identificar tweets que contienen esas palabras clave\n",
    "trafico['sinkhole_related'] = trafico['rawContent'].apply(lambda x: any(keyword in x for keyword in keywords_sinkhole))\n",
    "trafico['university_related'] = trafico['rawContent'].apply(lambda x: any(keyword in x for keyword in keywords_university))\n",
    "\n",
    "# Contar tweets diarios relacionados con el socavón y la universidad\n",
    "conteo_diario_2023 = trafico[trafico['date'].astype('datetime64').dt.year == 2023].groupby(trafico['date'].astype('datetime64').dt.date)[['sinkhole_related', 'university_related']].sum()\n",
    "# Tomar solo los del 2023\n",
    "\n",
    "\n",
    "# Graficar menciones de socavón\n",
    "plt.figure(figsize=(15, 7))\n",
    "conteo_diario_2023['sinkhole_related'].plot(label='Menciones de socavón en zona 5', color='green')\n",
    "plt.title('Menciones diarias relacionadas con el socavón en zona 5')\n",
    "plt.ylabel('Número de menciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Graficar menciones de la universidad\n",
    "plt.figure(figsize=(15, 7))\n",
    "conteo_diario_2023['university_related'].plot(label='Menciones de la universidad', color='purple')\n",
    "plt.title('Menciones diarias relacionadas con la universidad')\n",
    "plt.ylabel('Número de menciones')\n",
    "plt.xlabel('Fecha')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***¿Cómo ha venido a complicar el tráfico en toda la ciudad la época de lluvia?***\n",
    "Como se puede observar, al graficar las menciones de lluvia y luego las menciones de tráfico, ambas tienen bastantes coincidencias en menciones por lo que se puede concluir que aunque no en todos los casos la lluvia sí afecta a la ciudad en épocas de lluvia. Especialmente en los últimos meses del año como se puede observar en el gráfico de barras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***¿El socavón de zona 5 ha tenido un impacto importante en el tráfico de la zona de la universidad?***\n",
    "\n",
    "Como se puede observar, en las ultimas dos graficas las cuales muestran los tweets de la zona 5 y de la zona de la universidad, se puede observar que el socavon de la zona 5 si ha tenido un impacto importante en el trafico de la zona de la universidad, ya que en la grafica de la zona 5 se puede observar una gran cantidad de tweets en los ultimos meses en los cuales se han tenido lo problemas del socavón, y en la grafica de la zona de la universidad se puede observar que la cantidad de tweets sobre trafico aumenta en las mismas fechas, haciendo referencia a que el socavón si ha tenido un impacto importante en el trafico de la zona de la universidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_polarity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "bernardo['polarity'] = bernardo['rawContent'].apply(get_polarity)\n",
    "\n",
    "polaridad = bernardo['polarity'].mean()\n",
    "\n",
    "print('Polaridad de los tweets de Bernardo: ', polaridad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los tweets son más neutros que positivos y negativos, esto se puede deber a que la mayoría de tweets son de noticias y no de opiniones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = bernardo[['retweetCount', 'likeCount', 'replyCount']].quantile(0.9).to_dict()\n",
    "percentiles\n",
    "\n",
    "influencer_tweets = bernardo[\n",
    "    ((bernardo['retweetCount'] > percentiles['retweetCount']) +\n",
    "     (bernardo['likeCount'] > percentiles['likeCount']) +\n",
    "     (bernardo['replyCount'] > percentiles['replyCount'])) >= 2\n",
    "]\n",
    "\n",
    "influencer_users = influencer_tweets['user'].tolist()\n",
    "\n",
    "unique_influencers = {}\n",
    "for user_info in influencer_users:\n",
    "    user_id = user_info['id']\n",
    "    if user_id not in unique_influencers:\n",
    "        unique_influencers[user_id] = {\n",
    "            \"username\": user_info['username'],\n",
    "            \"displayname\": user_info['displayname'],\n",
    "            \"url\": user_info['url']\n",
    "        }\n",
    "\n",
    "influencer_df = pd.DataFrame(unique_influencers.values())\n",
    "if influencer_df.empty:\n",
    "    print(\"No hay influencers.\")\n",
    "else:\n",
    "    print(\"Los influencers son:\", influencer_df['username'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ver los resultados se puede concluir que no hay influencers, porque ninguno de los usuarios que cumplan con al menos 2 requisitos. Por lo tanto no se encuentran influencers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de interacciones directas con Bernardo: 0\n",
      "Número de interacciones indirectas con Bernardo: 2643\n"
     ]
    }
   ],
   "source": [
    "direct_interactions = bernardo[bernardo['inReplyToUser'].apply(lambda x: isinstance(x, dict) and x['username'] == 'BArevalodeLeon')]\n",
    "\n",
    "print(\"Número de interacciones directas con Bernardo:\", len(direct_interactions))\n",
    "\n",
    "indirect_interactions = bernardo[\n",
    "    (bernardo['rawContent'].str.contains('BArevalodeLeon', case=False)) & \n",
    "    ~(bernardo['id'].isin(direct_interactions['id']))\n",
    "]\n",
    "\n",
    "print(\"Número de interacciones indirectas con Bernardo:\", len(indirect_interactions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este análilis se puede concluir que todas las interacciones con la cuenta de Bernardo Arévalo son neutras, que puede ser por que su contenido puede ser más inforamtivo que mostrando opiniones. Asimismo, las interacciones son indirectas es decir que no hay una conversación directa con el usuario sino que menciones a su cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polaridad de los tweets de Sandra:  0.014774158467660246\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "sandra['polarity'] = sandra['rawContent'].apply(get_polarity)\n",
    "\n",
    "polaridad = sandra['polarity'].mean()\n",
    "\n",
    "print('Polaridad de los tweets de Sandra: ', polaridad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la mayoría de tweets son neutros, esto se puede deber a que la mayoría de tweets son de noticias y no de opiniones al igual que con los datos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay influencers.\n"
     ]
    }
   ],
   "source": [
    "percentiles = sandra[['retweetCount', 'likeCount', 'replyCount']].quantile(0.9).to_dict()\n",
    "percentiles\n",
    "\n",
    "influencer_tweets = sandra[\n",
    "    ((sandra['retweetCount'] > percentiles['retweetCount']) +\n",
    "     (sandra['likeCount'] > percentiles['likeCount']) +\n",
    "     (sandra['replyCount'] > percentiles['replyCount'])) >= 2\n",
    "]\n",
    "\n",
    "influencer_users = influencer_tweets['user'].tolist()\n",
    "\n",
    "unique_influencers = {}\n",
    "for user_info in influencer_users:\n",
    "    user_id = user_info['id']\n",
    "    if user_id not in unique_influencers:\n",
    "        unique_influencers[user_id] = {\n",
    "            \"username\": user_info['username'],\n",
    "            \"displayname\": user_info['displayname'],\n",
    "            \"url\": user_info['url']\n",
    "        }\n",
    "\n",
    "influencer_df = pd.DataFrame(unique_influencers.values())\n",
    "if influencer_df.empty:\n",
    "    print(\"No hay influencers.\")\n",
    "else:\n",
    "    print(\"Los influencers son:\", influencer_df['username'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con los datos anteriores, se puede concluir que no hay influencers, porque ninguno de los usuarios que cumplan con al menos 2 requisitos. Por lo tanto no se encuentran influencers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de interacciones directas con Sandra: 0\n",
      "Número de interacciones indirectas con Sandra: 852\n"
     ]
    }
   ],
   "source": [
    "direct_interactions = sandra[sandra['inReplyToUser'].apply(lambda x: isinstance(x, dict) and x['username'] == 'SandraTorresGUA')]\n",
    "\n",
    "print(\"Número de interacciones directas con Sandra:\", len(direct_interactions))\n",
    "\n",
    "indirect_interactions = sandra[\n",
    "    (sandra['rawContent'].str.contains('SandraTorresGUA', case=False)) & \n",
    "    ~(sandra['id'].isin(direct_interactions['id']))\n",
    "]\n",
    "\n",
    "print(\"Número de interacciones indirectas con Sandra:\", len(indirect_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, tanto con Arevalo como con Sandra, las interacciones fueron indirectas indicando que su contenido era más informativo por el período de tiempo que está analziado. Asimismo no hay influencers en ninguno de los dos casos que cumplan con los requisitos, pero si pueden haber casos que personas con bastante seguidores compartieran este tipo de información. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haber reealizado todo el analisis de los datos sobre ambos candidatos se puede concluir que ambos tienen un contenido informativo y no de opiniones, esto con el fin de atraer a mayor cantidad de personas a sus cuentas. Pero realmente con la informacion que se tiene no se puede definir si las personas hayan sido influenciadas por los candidatos o por la informacion que ellos comparten. Pero si fue una de las meneras en las que ellos trataron de influenciar a las personas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
